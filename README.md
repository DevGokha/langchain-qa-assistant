LangChain Document Q&A Assistant
ğŸš€ Overview

The LangChain Document Q&A Assistant is a chatbot that answers questions from uploaded PDF/TXT documents using:

ğŸ” Document chunking

ğŸ§  Vector embeddings

ğŸ—„ Local vector database (Chroma)

ğŸ¤– Local LLM (Ollama â€“ Llama 3)

ğŸ§µ Conversation memory

ğŸ“ Source citation

ğŸŒ Streamlit interface

It is designed as a complete beginner-friendly project for learning document intelligence, retrieval-augmented generation (RAG), and LangChain.

ğŸ¯ Features
âœ” Core Features (Required)

Upload PDF or TXT documents

Document chunking using RecursiveCharacterTextSplitter

Local embeddings using HuggingFace MiniLM

Vector storage with Chroma DB (persistent)

Natural-language question answering

Context-aware responses

Source citation (file name + page number for PDFs)

Conversation memory (follow-up questions work)

LangChain retriever + Ollama LLM pipeline

â­ Bonus Features (Optional)

Multiple document support

Streamlit front-end

Conversation history panel

Download conversation history as JSON

Clean UI with expandable source panels

ğŸ—ï¸ Tech Stack
Component	Technology
LLM	Ollama (local) â€“ Llama 3
Embeddings	HuggingFace MiniLM
Vector DB	Chroma
Framework	LangChain
Front-end	Streamlit
Loader	PyPDFLoader, TextLoader
Language	Python 3.10+
ğŸ“ Folder Structure
LangChain-QA-Assistant/
â”‚â”€â”€ app.py                 # Streamlit UI
â”‚â”€â”€ qa_chain.py            # LLM + retrieval + memory logic
â”‚â”€â”€ ingest.py              # Document loading + chunking + vector DB
â”‚â”€â”€ config.py              # Path configuration
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ docs/                  # Optional sample documents
â”‚â”€â”€ vectorstore/           # Auto-created Chroma DB
â”‚â”€â”€ uploads/               # Uploaded files

âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the repository
git clone https://github.com/Devgokha/langchain-qa-assistant.git
cd langchain-qa-assistant

2ï¸âƒ£ Create virtual environment
python -m venv venv
venv\Scripts\activate   # Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Install Ollama

Download from:
https://ollama.com

Then run:

ollama pull llama3
ollama serve


Keep Ollama running.

â–¶ï¸ Running the App
streamlit run app.py


Then open:
ğŸ‘‰ http://localhost:8501

ğŸ–¼ How to Use

Upload one or multiple PDF/TXT documents

Click Process Documents

Ask any question

View the answer + source citations

Download the conversation as JSON if needed

âœ¨ Example Questions

What is Artificial Intelligence?

Explain machine learning in simple terms.

What are the applications mentioned in the document?

Give a summary of the uploaded document.

What does the document say about reasoning?



âœ” Evaluation Criteria (Satisfied)

Functionality (40%) â€“ Works fully with RAG, citations, memory

Code Quality (25%) â€“ Modular (qa_chain.py, ingest.py, etc.)

Documentation (20%) â€“ This README + explanation

User Experience (15%) â€“ Clear Streamlit UI

ğŸ™Œ Author

Dev Gokha
MERN + AI/ML Developer
Passionate about RAG, LangChain, and applied AI engineering.